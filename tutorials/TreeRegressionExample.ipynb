{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Example\n",
    "This notebook is for illustrating the effects of adversarial transformers on a progressive learner for regression. We will run toy experiments with a normally trained transformer and an adversarial transformer in the same progressive learner using a SimpleAverage decider. With this toy example, we train the normal transformer on the data y=x.\n",
    "\n",
    "We will run 3 experiments using an adversarial transformer:\n",
    "1. that outputs random partitions\n",
    "2. that is trained on y=0 data\n",
    "3. that is trained on very noisy y=x data\n",
    "\n",
    "To show that adversarial transformers are bad, we would expect the generalization error of the data predicted by the adversarial transformer to be higher than that of the normal transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import log2, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proglearn.progressive_learner import ProgressiveLearner\n",
    "from proglearn.deciders import SimpleAverage, LinearRegressionDecider\n",
    "from proglearn.transformers import TreeRegressionTransformer\n",
    "from proglearn.voters import TreeRegressionVoter\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Adversarial transformer trained on y=0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope = [[1.]]\n",
      "intercept = [2.77555756e-17]\n",
      "y = [1.]x + [2.77555756e-17]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create the Task A dataset\n",
    "X, y, coef = make_regression(n_samples=1000, n_features=1, n_informative=1, noise=0.1, coef=True, bias=0.0)\n",
    "\n",
    "#Use linear regression to find the true values\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "\n",
    "#Plot the actual Task A data of y = x\n",
    "y = (y - regressor.intercept_) / regressor.coef_\n",
    "y = y.reshape(X.shape[0], -1)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "a1 = fig.add_subplot(1,2,1)\n",
    "a2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "a1.scatter(X, y)\n",
    "a1.set_title('Task A Data Distribution')\n",
    "a1.set_xlabel('X')\n",
    "a1.set_ylabel('Labels')\n",
    "a1.set_xlim([-5, 5])\n",
    "a1.set_ylim([-5, 5])\n",
    "\n",
    "print('slope = ' + str(regressor.coef_))\n",
    "print('intercept = ' + str(regressor.intercept_))\n",
    "print('y = ' + str(regressor.coef_[0]) + 'x + ' + str(regressor.intercept_))\n",
    "\n",
    "task_A_data = np.append(X, y, axis=1)\n",
    "\n",
    "#Task B data\n",
    "X, y, coef = make_regression(n_samples=1000, n_features=1, n_informative=1, noise=0.1, coef=True, bias=0.0)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "y = np.zeros((X.shape[0], 1))\n",
    "\n",
    "a2.scatter(X, y)\n",
    "a2.set_title('Task B Data Distribution')\n",
    "a2.set_xlabel('X')\n",
    "a2.set_ylabel('Labels')\n",
    "a2.set_xlim([-5, 5])\n",
    "a2.set_ylim([-5, 5])\n",
    "\n",
    "task_B_data = np.append(X, y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExp2Data(sample_size):\n",
    "    # Create the Task A dataset\n",
    "    X, y, coef = make_regression(n_samples=sample_size, n_features=1, n_informative=1, noise=0.1, coef=True, bias=0.0)\n",
    "\n",
    "    # Use linear regression to find the true values\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X, y)\n",
    "    \n",
    "    # Rescale y = mx + b to be y* = x, where y* = (y - b) / m\n",
    "    y = (y - regressor.intercept_) / regressor.coef_\n",
    "    y = y.reshape(X.shape[0], -1)\n",
    "    \n",
    "    task_A_data = np.append(X, y, axis=1)\n",
    "    \n",
    "    # Test B data\n",
    "    X_new, y_new = make_regression(n_samples=sample_size, n_features=1, n_informative=1, noise=0.1, bias=0.0)\n",
    "    regressor.fit(X_new, y_new)\n",
    "    y_new = np.zeros((X_new.shape[0], 1))\n",
    "    task_B_data = np.append(X_new, y_new, axis=1)\n",
    "    \n",
    "    return task_A_data, task_B_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment2(n_task_A, n_task_B, n_test=0.25, n_trees=10, max_depth=None, cur_depth=None, acorn=None):\n",
    "    \n",
    "    if acorn != None:\n",
    "        np.random.seed(acorn)\n",
    "        \n",
    "    errors = np.zeros(3, dtype=float)\n",
    "    \n",
    "    transformer_voter_decider_split = [0.67, 0.33, 0]\n",
    "    \n",
    "    default_transformer_class = TreeRegressionTransformer\n",
    "    taskA_transformer_kwargs = {\"kwargs\": {\"max_depth\": max_depth}}\n",
    "    taskB_transformer_kwargs = {\"kwargs\": {\"max_depth\": cur_depth}}\n",
    "\n",
    "    #Not implemented\n",
    "#     taskB_transformer_class = TreeRegressionRandomTransformer\n",
    "\n",
    "    default_voter_class = TreeRegressionVoter\n",
    "    default_voter_kwargs = {}\n",
    "\n",
    "    default_decider_class = SimpleAverage\n",
    "    default_decider_kwargs = {}\n",
    "\n",
    "    progressive_learner = ProgressiveLearner(default_transformer_class = default_transformer_class, \n",
    "                                             default_transformer_kwargs = taskA_transformer_kwargs,\n",
    "                                             default_voter_class = default_voter_class,\n",
    "                                             default_voter_kwargs = default_voter_kwargs,\n",
    "                                             default_decider_class = default_decider_class,\n",
    "                                             default_decider_kwargs = default_decider_kwargs)\n",
    "\n",
    "    # Create data\n",
    "    taskA_data, taskB_data = createExp2Data(n_task_A)\n",
    "    \n",
    "    # Split task data into train/test\n",
    "    taskA_x_train, taskA_x_test, taskA_label_train, taskA_label_test = train_test_split(taskA_data[:,0], \n",
    "                                                                                        taskA_data[:,1], \n",
    "                                                                                        test_size=n_test, \n",
    "                                                                                        random_state=7)\n",
    "\n",
    "    taskB_x_train, taskB_x_test, taskB_label_train, taskB_label_test = train_test_split(taskB_data[:,0], \n",
    "                                                                                        taskB_data[:,1], \n",
    "                                                                                        test_size=n_test, \n",
    "                                                                                        random_state=7)\n",
    "    \n",
    "    taskA_x_train = taskA_x_train.reshape(-1, 1)\n",
    "    taskA_x_test = taskA_x_test.reshape(-1, 1)\n",
    "    taskA_label_train = taskA_label_train.reshape(-1, 1)\n",
    "    taskA_label_test = taskA_label_test.reshape(-1, 1)\n",
    "\n",
    "    taskB_x_train = taskB_x_train.reshape(-1, 1)\n",
    "    taskB_x_test = taskB_x_test.reshape(-1, 1)\n",
    "    taskB_label_train = taskB_label_train.reshape(-1, 1)\n",
    "    taskB_label_test = taskB_label_test.reshape(-1, 1)\n",
    "\n",
    "    if (n_task_A == 0):\n",
    "        progressive_learner.add_task(taskB_x_train, taskB_label_train)\n",
    "        l2f_taskB = progressive_learner.predict(taskB_x_test, transformer_ids=[0], task_id=0)\n",
    "\n",
    "        errors[0] = 0.5\n",
    "        errors[1] = mean_squared_error(lf2_taskB, taskB_label_test)\n",
    "        \n",
    "    elif (n_task_B == 0):\n",
    "        progressive_learner.add_task(taskA_x_train, taskA_label_train)\n",
    "        l2f_taskA = progressive_learner.predict(taskA_x_test, transformer_ids=[0], task_id=0)\n",
    "\n",
    "        errors[0] = mean_squared_error(l2f_taskA, taskA_label_test)\n",
    "        errors[1] = 0.5\n",
    "        \n",
    "    else:\n",
    "        # Add tasks to progressive learner\n",
    "        progressive_learner.add_task(taskA_x_train, taskA_label_train)\n",
    "#         progressive_learner.add_task(taskB_x_train, taskB_label_train)\n",
    "        \n",
    "        # Predict and record loss without adversarial transformer\n",
    "        l2f_taskA = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[0], task_id=0)\n",
    "        errors[0] = mean_squared_error(l2f_taskA, taskA_label_test)\n",
    "        \n",
    "        # Create adversarial transformer\n",
    "        progressive_learner.add_transformer(taskB_x_train, taskB_label_train,\n",
    "                                            transformer_class=default_transformer_class,\n",
    "                                            transformer_kwargs=taskB_transformer_kwargs,\n",
    "                                            voter_class=default_voter_class,\n",
    "                                            voter_kwargs=default_voter_kwargs,\n",
    "                                            transformer_id=1\n",
    "                                           )\n",
    "        # Predict and record loss with adversarial transformer\n",
    "        l2f_taskA_adversarial = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[0, 1], task_id=0)\n",
    "        errors[1] = mean_squared_error(l2f_taskA_adversarial, taskA_label_test)\n",
    "        \n",
    "        # Predict with inference through adversarial \n",
    "        l2f_taskA_adversarial_only = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[1], task_id=0)\n",
    "        errors[2] = mean_squared_error(l2f_taskA_adversarial_only, taskA_label_test)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    3.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    3.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    3.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.8s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the tree parameters\n",
    "mc_rep = 100\n",
    "n_test = 0.25\n",
    "n_trees = 10\n",
    "n_sample_size = 1000\n",
    "max_depth = 30\n",
    "\n",
    "range_depths = (100*np.arange(0.01, 0.31, step=0.01)).astype(int)\n",
    "\n",
    "# Initiate error arrays\n",
    "mean_error = np.zeros((3, len(range_depths)))\n",
    "std_error = np.zeros((3, len(range_depths)))\n",
    "\n",
    "# Initiate transfer efficiencies\n",
    "mean_te = np.zeros((1, len(range_depths)))\n",
    "std_te = np.zeros((1, len(range_depths)))\n",
    "\n",
    "# Iterate over the depths\n",
    "for i, n1 in enumerate(range_depths):\n",
    "    print('starting to compute, depth=%s\\n' %n1)\n",
    "    error = np.array(\n",
    "        Parallel(n_jobs=-1, verbose=1)(\n",
    "            delayed(experiment2)(\n",
    "                n_sample_size, n_sample_size, n_test=n_test, n_trees=n_trees, cur_depth=n1, max_depth=max_depth\n",
    "            ) for _ in range(mc_rep)\n",
    "        )\n",
    "    )\n",
    "    mean_error[:, i] = np.mean(error, axis=0)\n",
    "    std_error[:, i] = np.std(error, ddof=1, axis=0)\n",
    "    \n",
    "    mean_te[0, i] = np.mean(error[:, 0]) / np.mean(error[:, 1])\n",
    "        \n",
    "\n",
    "with open('./data/mean_setting2.pickle', 'wb') as f:\n",
    "    pickle.dump(mean_error, f)\n",
    "    \n",
    "with open('./data/std_setting2', 'wb') as f:\n",
    "    pickle.dump(std_error, f)\n",
    "\n",
    "with open('./data/mean_te_setting2', 'wb') as f:\n",
    "    pickle.dump(mean_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "Adversarial transformer trained on noisy, low-sampled, y=x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope = [[1.]]\n",
      "intercept = [0.]\n",
      "y = [1.]x + [0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create the Task A dataset\n",
    "X, y, coef = make_regression(n_samples=1000, n_features=1, n_informative=1, noise=0.1, coef=True, bias=0.0)\n",
    "\n",
    "#Use linear regression to find the true values\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "\n",
    "#Plot the actual Task A data of y = x\n",
    "y = (y - regressor.intercept_) / regressor.coef_\n",
    "y = y.reshape(X.shape[0], -1)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "a1 = fig.add_subplot(1,2,1)\n",
    "a2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "a1.scatter(X, y)\n",
    "a1.set_title('Task A Data Distribution')\n",
    "a1.set_xlabel('X')\n",
    "a1.set_ylabel('Labels')\n",
    "a1.set_xlim([-5, 5])\n",
    "a1.set_ylim([-5, 5])\n",
    "\n",
    "print('slope = ' + str(regressor.coef_))\n",
    "print('intercept = ' + str(regressor.intercept_))\n",
    "print('y = ' + str(regressor.coef_[0]) + 'x + ' + str(regressor.intercept_))\n",
    "\n",
    "task_A_data = np.append(X, y, axis=1)\n",
    "\n",
    "#Task B data\n",
    "X_new, y_new = make_regression(n_samples=int(ceil(np.sqrt(1000))/2), n_features=1, n_informative=1, noise=2.0, bias=0.0)\n",
    "regressor.fit(X_new, y_new)\n",
    "y_new = (y_new - regressor.intercept_) / regressor.coef_\n",
    "y_new = y_new.reshape(X_new.shape[0], -1)\n",
    "task_B_data = np.append(X_new, y_new, axis=1)\n",
    "\n",
    "a2.scatter(X_new, y_new)\n",
    "a2.set_title('Task B Data Distribution')\n",
    "a2.set_xlabel('X')\n",
    "a2.set_ylabel('Labels')\n",
    "a2.set_xlim([-5, 5])\n",
    "a2.set_ylim([-5, 5])\n",
    "\n",
    "task_B_data = np.append(X_new, y_new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExp3Data(sample_size):\n",
    "    # Create the Task A dataset\n",
    "    X, y, coef = make_regression(n_samples=sample_size, n_features=1, n_informative=1, noise=0.1, coef=True, bias=0.0)\n",
    "\n",
    "    # Use linear regression to find the true values\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X, y)\n",
    "    \n",
    "    # Rescale y = mx + b to be y* = x, where y* = (y - b) / m\n",
    "    y = (y - regressor.intercept_) / regressor.coef_\n",
    "    y = y.reshape(X.shape[0], -1)\n",
    "    \n",
    "    task_A_data = np.append(X, y, axis=1)\n",
    "    \n",
    "    # Test B data\n",
    "    sampleB = int(ceil(np.sqrt(sample_size)))\n",
    "    X_new, y_new = make_regression(n_samples=int(sampleB/2), n_features=1, n_informative=1, noise=2.0, bias=0.0)\n",
    "    regressor.fit(X_new, y_new)\n",
    "    y_new = (y_new - regressor.intercept_) / regressor.coef_\n",
    "    y_new = y_new.reshape(X_new.shape[0], -1)\n",
    "    task_B_data = np.append(X_new, y_new, axis=1)\n",
    "    \n",
    "    return task_A_data, task_B_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment3(n_task_A, n_task_B, n_test=0.25, n_trees=10, max_depth=None, cur_depth=None, acorn=None):\n",
    "    \n",
    "    if acorn != None:\n",
    "        np.random.seed(acorn)\n",
    "        \n",
    "    errors = np.zeros(3, dtype=float)\n",
    "    \n",
    "    transformer_voter_decider_split = [0.67, 0.33, 0]\n",
    "    \n",
    "    default_transformer_class = TreeRegressionTransformer\n",
    "    taskA_transformer_kwargs = {\"kwargs\": {\"max_depth\": max_depth}}\n",
    "    taskB_transformer_kwargs = {\"kwargs\": {\"max_depth\": cur_depth}}\n",
    "\n",
    "    #Not implemented\n",
    "#     taskB_transformer_class = TreeRegressionRandomTransformer\n",
    "\n",
    "    default_voter_class = TreeRegressionVoter\n",
    "    default_voter_kwargs = {}\n",
    "\n",
    "    default_decider_class = SimpleAverage\n",
    "    default_decider_kwargs = {}\n",
    "\n",
    "    progressive_learner = ProgressiveLearner(default_transformer_class = default_transformer_class, \n",
    "                                             default_transformer_kwargs = taskA_transformer_kwargs,\n",
    "                                             default_voter_class = default_voter_class,\n",
    "                                             default_voter_kwargs = default_voter_kwargs,\n",
    "                                             default_decider_class = default_decider_class,\n",
    "                                             default_decider_kwargs = default_decider_kwargs)\n",
    "\n",
    "    # Create data\n",
    "    taskA_data, taskB_data = createExp3Data(n_task_A)\n",
    "    \n",
    "    # Split task data into train/test\n",
    "    taskA_x_train, taskA_x_test, taskA_label_train, taskA_label_test = train_test_split(taskA_data[:,0], \n",
    "                                                                                        taskA_data[:,1], \n",
    "                                                                                        test_size=n_test, \n",
    "                                                                                        random_state=7)\n",
    "\n",
    "    taskB_x_train, taskB_x_test, taskB_label_train, taskB_label_test = train_test_split(taskB_data[:,0], \n",
    "                                                                                        taskB_data[:,1], \n",
    "                                                                                        test_size=n_test, \n",
    "                                                                                        random_state=7)\n",
    "    \n",
    "    taskA_x_train = taskA_x_train.reshape(-1, 1)\n",
    "    taskA_x_test = taskA_x_test.reshape(-1, 1)\n",
    "    taskA_label_train = taskA_label_train.reshape(-1, 1)\n",
    "    taskA_label_test = taskA_label_test.reshape(-1, 1)\n",
    "\n",
    "    taskB_x_train = taskB_x_train.reshape(-1, 1)\n",
    "    taskB_x_test = taskB_x_test.reshape(-1, 1)\n",
    "    taskB_label_train = taskB_label_train.reshape(-1, 1)\n",
    "    taskB_label_test = taskB_label_test.reshape(-1, 1)\n",
    "\n",
    "    if (n_task_A == 0):\n",
    "        progressive_learner.add_task(taskB_x_train, taskB_label_train)\n",
    "        l2f_taskB = progressive_learner.predict(taskB_x_test, transformer_ids=[0], task_id=0)\n",
    "\n",
    "        errors[0] = 0.5\n",
    "        errors[1] = mean_squared_error(lf2_taskB, taskB_label_test)\n",
    "        \n",
    "    elif (n_task_B == 0):\n",
    "        progressive_learner.add_task(taskA_x_train, taskA_label_train)\n",
    "        l2f_taskA = progressive_learner.predict(taskA_x_test, transformer_ids=[0], task_id=0)\n",
    "\n",
    "        errors[0] = mean_squared_error(l2f_taskA, taskA_label_test)\n",
    "        errors[1] = 0.5\n",
    "        \n",
    "    else:\n",
    "        # Add tasks to progressive learner\n",
    "        progressive_learner.add_task(taskA_x_train, taskA_label_train)\n",
    "#         progressive_learner.add_task(taskB_x_train, taskB_label_train)\n",
    "        \n",
    "        # Predict and record loss without adversarial transformer\n",
    "        l2f_taskA = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[0], task_id=0)\n",
    "        errors[0] = mean_squared_error(l2f_taskA, taskA_label_test)\n",
    "        \n",
    "        # Create adversarial transformer\n",
    "        progressive_learner.add_transformer(taskB_x_train, taskB_label_train,\n",
    "                                            transformer_class=default_transformer_class,\n",
    "                                            transformer_kwargs=taskB_transformer_kwargs,\n",
    "                                            voter_class=default_voter_class,\n",
    "                                            voter_kwargs=default_voter_kwargs,\n",
    "                                            transformer_id=1\n",
    "                                           )\n",
    "        # Predict and record loss with adversarial transformer\n",
    "        l2f_taskA_adversarial = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[0, 1], task_id=0)\n",
    "        errors[1] = mean_squared_error(l2f_taskA_adversarial, taskA_label_test)\n",
    "        \n",
    "        # Predict with inference through adversarial \n",
    "        l2f_taskA_adversarial_only = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[1], task_id=0)\n",
    "        errors[2] = mean_squared_error(l2f_taskA_adversarial_only, taskA_label_test)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   14.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the tree parameters\n",
    "mc_rep = 100\n",
    "n_test = 0.25\n",
    "n_trees = 10\n",
    "n_sample_size = 1000\n",
    "max_depth = 30\n",
    "\n",
    "range_depths = (100*np.arange(0.01, 0.31, step=0.01)).astype(int)\n",
    "\n",
    "# Initiate error arrays\n",
    "mean_error = np.zeros((3, len(range_depths)))\n",
    "std_error = np.zeros((3, len(range_depths)))\n",
    "\n",
    "# Initiate transfer efficiencies\n",
    "mean_te = np.zeros((1, len(range_depths)))\n",
    "std_te = np.zeros((1, len(range_depths)))\n",
    "\n",
    "# Iterate over the depths\n",
    "for i, n1 in enumerate(range_depths):\n",
    "    print('starting to compute, depth=%s\\n' %n1)\n",
    "    error = np.array(\n",
    "        Parallel(n_jobs=-1, verbose=1)(\n",
    "            delayed(experiment)(\n",
    "                n_sample_size, n_sample_size, n_test=n_test, n_trees=n_trees, cur_depth=n1, max_depth=max_depth\n",
    "            ) for _ in range(mc_rep)\n",
    "        )\n",
    "    )\n",
    "    mean_error[:, i] = np.mean(error, axis=0)\n",
    "    std_error[:, i] = np.std(error, ddof=1, axis=0)\n",
    "    \n",
    "    mean_te[0, i] = np.mean(error[:, 0]) / np.mean(error[:, 1])\n",
    "        \n",
    "\n",
    "with open('./data/mean_setting3.pickle', 'wb') as f:\n",
    "    pickle.dump(mean_error, f)\n",
    "    \n",
    "with open('./data/std_setting3', 'wb') as f:\n",
    "    pickle.dump(std_error, f)\n",
    "\n",
    "with open('./data/mean_te_setting3', 'wb') as f:\n",
    "    pickle.dump(mean_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean MSE')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x000001FE637C03A8> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     41\u001b[0m             display(\n\u001b[0;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2191\u001b[0m                            else suppress())\n\u001b[0;32m   2192\u001b[0m                     \u001b[1;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2193\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2195\u001b[0m                     bbox_inches = self.figure.get_tightbbox(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1852\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_constrained_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1854\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_constrained_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1855\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mexecute_constrained_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrenderer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2565\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayoutbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2566\u001b[1;33m         \u001b[0mdo_constrained_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2568\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delete_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"3.2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"renderer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\matplotlib\\_constrained_layout.py\u001b[0m in \u001b[0;36mdo_constrained_layout\u001b[1;34m(fig, renderer, h_pad, w_pad, hspace, wspace)\u001b[0m\n\u001b[0;32m    193\u001b[0m                     \u001b[1;31m# have the correct arrangement.  It just stacks the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[1;31m# subplot layoutboxes in the correct order...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m                     \u001b[0m_arrange_subplotspecs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwspace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\matplotlib\\_constrained_layout.py\u001b[0m in \u001b[0;36m_arrange_subplotspecs\u001b[1;34m(gs, hspace, wspace)\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mlayoutbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mss0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layoutbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layoutbox\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcolspan1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcolspan0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                 \u001b[0mlayoutbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mss1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layoutbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layoutbox\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;31m# vertical alignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[0mpad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhspace\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\matplotlib\\_layoutbox.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(boxes, padding, strength)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mstrength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('data/mean_setting2.pickle','rb') as f:\n",
    "    mean_error = pickle.load(f)\n",
    "\n",
    "range_depths = (100*np.arange(0.01, 0.31, step=0.01)).astype(int)\n",
    "\n",
    "fig = plt.figure(constrained_layout=True,figsize=(21,30))\n",
    "gs = fig.add_gridspec(30, 21)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[:6,:6])\n",
    "ax2.scatter(range_depths, mean_error[0,:], label='Task A with Normal')\n",
    "ax2.scatter(range_depths, mean_error[1,:], label='Task A with Normal + Adverserial')\n",
    "ax2.scatter(range_depths, mean_error[2,:], label='Task A with Adversarial')\n",
    "ax2.legend(loc='right', frameon=False)\n",
    "ax2.set_xlabel('Depth')\n",
    "ax2.set_ylabel('Mean MSE')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[7:13,2:9])\n",
    "\n",
    "with open('data/mean_setting3.pickle','rb') as f:\n",
    "    mean_error = pickle.load(f)\n",
    "\n",
    "ax3.scatter(range_depths, mean_error[0,:], label='Task A with Normal')\n",
    "ax3.scatter(range_depths, mean_error[1,:], label='Task A with Normal + Adverserial')\n",
    "ax3.scatter(range_depths, mean_error[2,:], label='Task A with Adversarial')\n",
    "ax3.legend(loc='right', frameon=False)\n",
    "ax3.set_xlabel('Depth')\n",
    "ax3.set_ylabel('Mean MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
