{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Example: Depth\n",
    "This notebook is for illustrating the effects of adversarial transformers on a progressive learner for regression. We will run toy experiments with a normally trained transformer and an adversarial transformer in the same progressive learner using a SimpleAverage decider. With this toy example, we train the normal transformer on the data y = x and will be iterating over a depth of 1-30 with 10 trees.\n",
    "\n",
    "We will run 3 experiments using an adversarial transformer:\n",
    "1. that outputs random partitions\n",
    "2. that is trained on y = 0 data\n",
    "3. that is trained on very noisy y = x data\n",
    "\n",
    "To show that adversarial transformers are bad, we would expect the generalization error of the data predicted by the adversarial transformer to be higher than that of the normal transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import log2, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proglearn.progressive_learner import ProgressiveLearner\n",
    "from proglearn.deciders import SimpleAverage, LinearRegressionDecider\n",
    "from proglearn.transformers import TreeRegressionTransformer\n",
    "# from proglearn.transformers import RandomTransformer\n",
    "from proglearn.voters import TreeRegressionVoter\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates the experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExperimentData(sample_size, exp2=False):\n",
    "    # Create the Task A dataset\n",
    "    X, y, coef = make_regression(n_samples=sample_size, n_features=1, n_informative=1, noise=0.1, coef=True, bias=0.0)\n",
    "\n",
    "    # Use linear regression to find the true values\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X, y)\n",
    "    \n",
    "    # Rescale y = mx + b to be y* = x, where y* = (y - b) / m\n",
    "    y = (y - regressor.intercept_) / regressor.coef_\n",
    "    y = y.reshape(X.shape[0], -1)\n",
    "    \n",
    "    task_A_data = np.append(X, y, axis=1)\n",
    "    \n",
    "    # Test B data\n",
    "    if exp2==True:\n",
    "        X_new, y_new = make_regression(n_samples=sample_size, n_features=1, n_informative=1, noise=0.1, bias=0.0)\n",
    "        regressor.fit(X_new, y_new)\n",
    "        y_new = np.zeros((X_new.shape[0], 1))\n",
    "    elif exp2==False:\n",
    "        X_new, y_new = make_regression(n_samples=int(sample_size / 10), n_features=1, n_informative=1, noise=10.0, bias=0.0)\n",
    "        regressor.fit(X_new, y_new)\n",
    "        y_new = (y_new - regressor.intercept_) / regressor.coef_\n",
    "        y_new = y_new.reshape(X_new.shape[0], -1)\n",
    "        y_new += np.random.normal(size=y_new.shape, scale=20.0)\n",
    "        plt.plot(X_new, y_new)\n",
    "\n",
    "    task_B_data = np.append(X_new, y_new, axis=1)\n",
    "    \n",
    "    return task_A_data, task_B_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(n_task_A, n_task_B, n_test=0.25, n_trees_A=25, n_trees_B=25, n_depth_A=30, \n",
    "               n_depth_B=30, zeros=False, randomTransformer=False, acorn=None):\n",
    "    \n",
    "    if acorn != None:\n",
    "        np.random.seed(acorn)\n",
    "        \n",
    "    errors = np.zeros(3, dtype=float)\n",
    "    \n",
    "    transformer_voter_decider_split = [0.67, 0.33, 0]\n",
    "    \n",
    "    default_transformer_class = TreeRegressionTransformer\n",
    "    taskA_transformer_kwargs = {\"kwargs\": {\"max_depth\": n_depth_A}}\n",
    "    taskB_transformer_kwargs = {\"kwargs\": {\"max_depth\": n_depth_B}}\n",
    "\n",
    "    default_voter_class = TreeRegressionVoter\n",
    "    default_voter_kwargs = {}\n",
    "\n",
    "    default_decider_class = SimpleAverage\n",
    "    default_decider_kwargs = {}\n",
    "\n",
    "    progressive_learner = ProgressiveLearner(default_transformer_class = default_transformer_class, \n",
    "                                             default_transformer_kwargs = taskA_transformer_kwargs,\n",
    "                                             default_voter_class = default_voter_class,\n",
    "                                             default_voter_kwargs = default_voter_kwargs,\n",
    "                                             default_decider_class = default_decider_class,\n",
    "                                             default_decider_kwargs = default_decider_kwargs)\n",
    "\n",
    "    # Create data\n",
    "    taskA_data, taskB_data = createExperimentData(n_task_A, zeros)\n",
    "    \n",
    "    # Split task data into train/test\n",
    "    taskA_x_train, taskA_x_test, taskA_label_train, taskA_label_test = train_test_split(taskA_data[:,0], \n",
    "                                                                                        taskA_data[:,1], \n",
    "                                                                                        test_size=n_test, \n",
    "                                                                                        random_state=7)\n",
    "\n",
    "    taskB_x_train, taskB_x_test, taskB_label_train, taskB_label_test = train_test_split(taskB_data[:,0], \n",
    "                                                                                        taskB_data[:,1], \n",
    "                                                                                        test_size=n_test, \n",
    "                                                                                        random_state=7)\n",
    "    \n",
    "    taskA_x_train = taskA_x_train.reshape(-1, 1)\n",
    "    taskA_x_test = taskA_x_test.reshape(-1, 1)\n",
    "    taskA_label_train = taskA_label_train.reshape(-1, 1)\n",
    "    taskA_label_test = taskA_label_test.reshape(-1, 1)\n",
    "\n",
    "    taskB_x_train = taskB_x_train.reshape(-1, 1)\n",
    "    taskB_x_test = taskB_x_test.reshape(-1, 1)\n",
    "    taskB_label_train = taskB_label_train.reshape(-1, 1)\n",
    "    taskB_label_test = taskB_label_test.reshape(-1, 1)\n",
    "\n",
    "    if (n_task_A == 0):\n",
    "        progressive_learner.add_task(taskB_x_train, taskB_label_train)\n",
    "        l2f_taskB = progressive_learner.predict(taskB_x_test, transformer_ids=[0], task_id=0)\n",
    "\n",
    "        errors[0] = 0.5\n",
    "        errors[1] = mean_squared_error(lf2_taskB, taskB_label_test)\n",
    "        \n",
    "    elif (n_task_B == 0):\n",
    "        progressive_learner.add_task(taskA_x_train, taskA_label_train)\n",
    "        l2f_taskA = progressive_learner.predict(taskA_x_test, transformer_ids=[0], task_id=0)\n",
    "\n",
    "        errors[0] = mean_squared_error(l2f_taskA, taskA_label_test)\n",
    "        errors[1] = 0.5\n",
    "        \n",
    "    else:\n",
    "        # Add tasks to progressive learner\n",
    "        progressive_learner.add_task(taskA_x_train, taskA_label_train)\n",
    "        \n",
    "        # Predict and record loss without adversarial transformer\n",
    "        l2f_taskA = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[0], task_id=0)\n",
    "        errors[0] = mean_squared_error(l2f_taskA, taskA_label_test)\n",
    "        \n",
    "        # Create adversarial transformer\n",
    "        if (randomTransformer):\n",
    "            progressive_learner.add_transformer(taskB_x_train, taskB_label_train,\n",
    "                                                transformer_class=TreeRegressionRandomTransformer,\n",
    "                                                transformer_kwargs=taskB_transformer_kwargs,\n",
    "                                                voter_class=default_voter_class,\n",
    "                                                voter_kwargs=default_voter_kwargs,\n",
    "                                                transformer_id=1\n",
    "                                               )\n",
    "        else:\n",
    "            progressive_learner.add_transformer(taskB_x_train, taskB_label_train,\n",
    "                                                transformer_class=default_transformer_class,\n",
    "                                                transformer_kwargs=taskB_transformer_kwargs,\n",
    "                                                voter_class=default_voter_class,\n",
    "                                                voter_kwargs=default_voter_kwargs,\n",
    "                                                transformer_id=1\n",
    "                                               )\n",
    "\n",
    "        # Predict and record loss with adversarial transformer\n",
    "        l2f_taskA_adversarial = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[0, 1], task_id=0)\n",
    "        errors[1] = mean_squared_error(l2f_taskA_adversarial, taskA_label_test)\n",
    "        \n",
    "        # Predict with inference through adversarial \n",
    "        l2f_taskA_adversarial_only = progressive_learner.predict_proba(taskA_x_test, transformer_ids=[1], task_id=0)\n",
    "        errors[2] = mean_squared_error(l2f_taskA_adversarial_only, taskA_label_test)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=1\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Parallel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6d70ea13381b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'starting to compute, depth=%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mn1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     error = np.array(\n\u001b[1;32m---> 22\u001b[1;33m         Parallel(n_jobs=-1, verbose=1)(\n\u001b[0m\u001b[0;32m     23\u001b[0m             delayed(experiment)(\n\u001b[0;32m     24\u001b[0m                 \u001b[0mn_sample_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_sample_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trees_A\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Parallel' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up the tree parameters\n",
    "mc_rep = 100\n",
    "n_test = 0.25\n",
    "n_trees = 25\n",
    "n_sample_size = 1000\n",
    "max_depth = 30\n",
    "\n",
    "range_depths = (100*np.arange(0.01, 0.31, step=0.01)).astype(int)\n",
    "\n",
    "# Initiate error arrays\n",
    "mean_error = np.zeros((3, len(range_depths)))\n",
    "std_error = np.zeros((3, len(range_depths)))\n",
    "\n",
    "# Initiate transfer efficiencies\n",
    "mean_te = np.zeros((1, len(range_depths)))\n",
    "std_te = np.zeros((1, len(range_depths)))\n",
    "\n",
    "# Iterate over the depths\n",
    "for i, n1 in enumerate(range_depths):\n",
    "    print('starting to compute, depth=%s\\n' %n1)\n",
    "    error = np.array(\n",
    "        Parallel(n_jobs=-1, verbose=1)(\n",
    "            delayed(experiment)(\n",
    "                n_sample_size, n_sample_size, n_test=n_test, n_trees_A=n_trees, \n",
    "                n_trees_B=n_trees, n_depth_A=max_depth, n_depth_B=n1, zeros=True\n",
    "            ) for _ in range(mc_rep)\n",
    "        )\n",
    "    )\n",
    "    mean_error[:, i] = np.mean(error, axis=0)\n",
    "    std_error[:, i] = np.std(error, ddof=1, axis=0)\n",
    "    \n",
    "    mean_te[0, i] = np.mean(error[:, 0]) / np.mean(error[:, 1])\n",
    "        \n",
    "\n",
    "with open('./data/mean_setting2.pickle', 'wb') as f:\n",
    "    pickle.dump(mean_error, f)\n",
    "    \n",
    "with open('./data/std_setting2', 'wb') as f:\n",
    "    pickle.dump(std_error, f)\n",
    "\n",
    "with open('./data/mean_te_setting2', 'wb') as f:\n",
    "    pickle.dump(mean_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "We will use an adversarial transformer trained on y = 0 data and a normal transformer trained on y = x data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    4.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    9.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    7.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    3.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    4.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    6.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    3.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    5.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    5.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the tree parameters\n",
    "mc_rep = 100\n",
    "n_test = 0.25\n",
    "n_trees = 25\n",
    "n_sample_size = 1000\n",
    "max_depth = 30\n",
    "\n",
    "range_depths = (100*np.arange(0.01, 0.31, step=0.01)).astype(int)\n",
    "\n",
    "# Initiate error arrays\n",
    "mean_error = np.zeros((3, len(range_depths)))\n",
    "std_error = np.zeros((3, len(range_depths)))\n",
    "\n",
    "# Initiate transfer efficiencies\n",
    "mean_te = np.zeros((1, len(range_depths)))\n",
    "std_te = np.zeros((1, len(range_depths)))\n",
    "\n",
    "# Iterate over the depths\n",
    "for i, n1 in enumerate(range_depths):\n",
    "    print('starting to compute, depth=%s\\n' %n1)\n",
    "    error = np.array(\n",
    "        Parallel(n_jobs=-1, verbose=1)(\n",
    "            delayed(experiment)(\n",
    "                n_sample_size, n_sample_size, n_test=n_test, n_trees_A=n_trees, \n",
    "                n_trees_B=n_trees, n_depth_A=max_depth, n_depth_B=n1, zeros=True\n",
    "            ) for _ in range(mc_rep)\n",
    "        )\n",
    "    )\n",
    "    mean_error[:, i] = np.mean(error, axis=0)\n",
    "    std_error[:, i] = np.std(error, ddof=1, axis=0)\n",
    "    \n",
    "    mean_te[0, i] = np.mean(error[:, 0]) / np.mean(error[:, 1])\n",
    "        \n",
    "\n",
    "with open('./data/mean_setting2.pickle', 'wb') as f:\n",
    "    pickle.dump(mean_error, f)\n",
    "    \n",
    "with open('./data/std_setting2', 'wb') as f:\n",
    "    pickle.dump(std_error, f)\n",
    "\n",
    "with open('./data/mean_te_setting2', 'wb') as f:\n",
    "    pickle.dump(mean_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "Adversarial transformer trained on noisy, low-sampled, y=x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, depth=17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up the tree parameters\n",
    "mc_rep = 100\n",
    "n_test = 0.25\n",
    "n_trees = 25\n",
    "n_sample_size = 1000\n",
    "max_depth = 30\n",
    "\n",
    "range_depths = (100*np.arange(0.01, 0.31, step=0.01)).astype(int)\n",
    "\n",
    "# Initiate error arrays\n",
    "mean_error = np.zeros((3, len(range_depths)))\n",
    "std_error = np.zeros((3, len(range_depths)))\n",
    "\n",
    "# Initiate transfer efficiencies\n",
    "mean_te = np.zeros((1, len(range_depths)))\n",
    "std_te = np.zeros((1, len(range_depths)))\n",
    "\n",
    "# Iterate over the depths\n",
    "for i, n1 in enumerate(range_depths):\n",
    "    print('starting to compute, depth=%s\\n' %n1)\n",
    "    error = np.array(\n",
    "        Parallel(n_jobs=-1, verbose=1)(\n",
    "            delayed(experiment)(\n",
    "                n_sample_size, n_sample_size, n_test=n_test, n_trees_A=n_trees, \n",
    "                n_trees_B=n_trees, n_depth_A=max_depth, n_depth_B=n1, zeros=False\n",
    "            ) for _ in range(mc_rep)\n",
    "        )\n",
    "    )\n",
    "    mean_error[:, i] = np.mean(error, axis=0)\n",
    "    std_error[:, i] = np.std(error, ddof=1, axis=0)\n",
    "    \n",
    "    mean_te[0, i] = np.mean(error[:, 0]) / np.mean(error[:, 1])\n",
    "        \n",
    "\n",
    "with open('./data/mean_setting3.pickle', 'wb') as f:\n",
    "    pickle.dump(mean_error, f)\n",
    "    \n",
    "with open('./data/std_setting3', 'wb') as f:\n",
    "    pickle.dump(std_error, f)\n",
    "\n",
    "with open('./data/mean_te_setting3', 'wb') as f:\n",
    "    pickle.dump(mean_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    3.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the tree parameters\n",
    "mc_rep = 100\n",
    "n_test = 0.25\n",
    "n_trees = 25\n",
    "n_sample_size = 1000\n",
    "max_depth = 30\n",
    "\n",
    "range_trees = (100*np.arange(0.05, 0.55, step=0.05)).astype(int)\n",
    "\n",
    "# Initiate error arrays\n",
    "mean_error = np.zeros((3, len(range_trees)))\n",
    "std_error = np.zeros((3, len(range_trees)))\n",
    "\n",
    "# Initiate transfer efficiencies\n",
    "mean_te = np.zeros((1, len(range_trees)))\n",
    "std_te = np.zeros((1, len(range_trees)))\n",
    "\n",
    "# Iterate over the depths\n",
    "for i, n1 in enumerate(range_trees):\n",
    "    print('starting to compute, tree=%s\\n' %n1)\n",
    "    error = np.array(\n",
    "        Parallel(n_jobs=-1, verbose=1)(\n",
    "            delayed(experiment)(\n",
    "                n_sample_size, n_sample_size, n_test=n_test, n_trees_A=n_trees, \n",
    "                n_trees_B=n1, n_depth_A=max_depth, n_depth_B=max_depth, zeros=True\n",
    "            ) for _ in range(mc_rep)\n",
    "        )\n",
    "    )\n",
    "    mean_error[:, i] = np.mean(error, axis=0)\n",
    "    std_error[:, i] = np.std(error, ddof=1, axis=0)\n",
    "    \n",
    "    mean_te[0, i] = np.mean(error[:, 0]) / np.mean(error[:, 1])\n",
    "        \n",
    "\n",
    "with open('./data/mean_setting4.pickle', 'wb') as f:\n",
    "    pickle.dump(mean_error, f)\n",
    "    \n",
    "with open('./data/std_setting4', 'wb') as f:\n",
    "    pickle.dump(std_error, f)\n",
    "\n",
    "with open('./data/mean_te_setting4', 'wb') as f:\n",
    "    pickle.dump(mean_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.7s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute, tree=50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    2.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the tree parameters\n",
    "mc_rep = 100\n",
    "n_test = 0.25\n",
    "n_trees = 25\n",
    "n_sample_size = 1000\n",
    "max_depth = 30\n",
    "\n",
    "range_trees = (100*np.arange(0.05, 0.55, step=0.05)).astype(int)\n",
    "\n",
    "# Initiate error arrays\n",
    "mean_error = np.zeros((3, len(range_trees)))\n",
    "std_error = np.zeros((3, len(range_trees)))\n",
    "\n",
    "# Initiate transfer efficiencies\n",
    "mean_te = np.zeros((1, len(range_trees)))\n",
    "std_te = np.zeros((1, len(range_trees)))\n",
    "\n",
    "# Iterate over the depths\n",
    "for i, n1 in enumerate(range_trees):\n",
    "    print('starting to compute, tree=%s\\n' %n1)\n",
    "    error = np.array(\n",
    "        Parallel(n_jobs=-1, verbose=1)(\n",
    "            delayed(experiment)(\n",
    "                n_sample_size, n_sample_size, n_test=n_test, n_trees_A=n_trees, \n",
    "                n_trees_B=n1, n_depth_A=max_depth, n_depth_B=max_depth, zeros=True\n",
    "            ) for _ in range(mc_rep)\n",
    "        )\n",
    "    )\n",
    "    mean_error[:, i] = np.mean(error, axis=0)\n",
    "    std_error[:, i] = np.std(error, ddof=1, axis=0)\n",
    "    \n",
    "    mean_te[0, i] = np.mean(error[:, 0]) / np.mean(error[:, 1])\n",
    "        \n",
    "\n",
    "with open('./data/mean_setting5.pickle', 'wb') as f:\n",
    "    pickle.dump(mean_error, f)\n",
    "    \n",
    "with open('./data/std_setting5', 'wb') as f:\n",
    "    pickle.dump(std_error, f)\n",
    "\n",
    "with open('./data/mean_te_setting5', 'wb') as f:\n",
    "    pickle.dump(mean_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mean_setting2.pickle','rb') as f:\n",
    "    mean_error_2 = pickle.load(f)\n",
    "    \n",
    "with open('data/mean_setting3.pickle','rb') as f:\n",
    "    mean_error_3 = pickle.load(f)\n",
    "    \n",
    "with open('data/mean_setting4.pickle','rb') as f:\n",
    "    mean_error_4 = pickle.load(f)\n",
    "    \n",
    "with open('data/mean_setting5.pickle','rb') as f:\n",
    "    mean_error_5 = pickle.load(f)\n",
    "\n",
    "range_depths = (100*np.arange(0.01, 0.31, step=0.01)).astype(int)\n",
    "range_trees = (100*np.arange(0.05, 0.55, step=0.05)).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(26,20))\n",
    "\n",
    "ax[0,0].scatter(range_depths, mean_error_2[0,:], s=10**2, label='Task A with Normal')\n",
    "ax[0,0].scatter(range_depths, mean_error_2[1,:], s=10**2, label='Task A with Normal + Adverserial')\n",
    "ax[0,0].scatter(range_depths, mean_error_2[2,:], s=10**2, label='Task A with Adversarial')\n",
    "ax[0,0].set_xlabel('Depth', fontsize=25)\n",
    "ax[0,0].set_ylabel('Mean MSE', fontsize=25)\n",
    "ax[0,0].set_title('Adversarial Transformer trained on y = 0', fontsize=25)\n",
    "ax[0,0].tick_params(labelsize=25)\n",
    "\n",
    "ax[0,1].scatter(range_depths, mean_error_3[0,:], s=10**2, label='Task A with Normal')\n",
    "ax[0,1].scatter(range_depths, mean_error_3[1,:], s=10**2, label='Task A with Normal + Adverserial')\n",
    "ax[0,1].scatter(range_depths, mean_error_3[2,:], s=10**2, label='Task A with Adversarial')\n",
    "ax[0,1].legend(loc='right', frameon=False, bbox_to_anchor=(1.8, 0.5), fontsize=25)\n",
    "ax[0,1].set_xlabel('Depth', fontsize=25)\n",
    "ax[0,1].set_ylabel('Mean MSE', fontsize=25)\n",
    "ax[0,1].set_title('Adversarial Transformer trained on noisy y = x', fontsize=25)\n",
    "ax[0,1].tick_params(labelsize=25)\n",
    "\n",
    "ax[1,0].scatter(range_trees, mean_error_4[0,:], s=10**2, label='Task A with Normal')\n",
    "ax[1,0].scatter(range_trees, mean_error_4[1,:], s=10**2, label='Task A with Normal + Adverserial')\n",
    "ax[1,0].scatter(range_trees, mean_error_4[2,:], s=10**2, label='Task A with Adversarial')\n",
    "ax[1,0].set_xlabel('Trees', fontsize=25)\n",
    "ax[1,0].set_ylabel('Mean MSE', fontsize=25)\n",
    "ax[1,0].set_title('Adversarial Transformer trained on y = 0', fontsize=25)\n",
    "ax[1,0].tick_params(labelsize=25)\n",
    "\n",
    "ax[1,1].scatter(range_trees, mean_error_5[0,:], s=10**2, label='Task A with Normal')\n",
    "ax[1,1].scatter(range_trees, mean_error_5[1,:], s=10**2, label='Task A with Normal + Adverserial')\n",
    "ax[1,1].scatter(range_trees, mean_error_5[2,:], s=10**2, label='Task A with Adversarial')\n",
    "ax[1,1].set_xlabel('Trees', fontsize=25)\n",
    "ax[1,1].set_ylabel('Mean MSE', fontsize=25)\n",
    "ax[1,1].set_title('Adversarial Transformer trained on noisy y = x', fontsize=25)\n",
    "ax[1,1].tick_params(labelsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
